**Провести анализ способов fine-tuning моделей**.

Результат анализа должен содержать:
1) Список существующих моделей-энкодеров с описанием их ТТХ (необходимой мощности для работы, latency одного запроса и подобного)
2) Методы дообучения этих моделей (прямое дообучение на наших данных, дестиляция знаний и т.д.). Конкретно для текстовых данных из archive.org, на которых будет работать наш поисковик.
   - Если есть возможность, то оценить необходимые вычислительные мощности для использования каждого из методов 
   -  Если есть возможность, то оценить прирост в качестве после дообучения

## Список моделей-кодировщиков
Данная работа уже была проделана. Результаты взяты с сайта: https://github.com/avidale/encodechka/tree/master

#### Лидерборд

Ранжирование моделей в по среднему качеству и производительности. 
Подсвечены Парето-оптимальные модели по каждому из критериев. 

| model                                                       | CPU       | GPU      | size          |   Mean S | Mean S+W   |   dim |
|:------------------------------------------------------------|:----------|:---------|:--------------|---------:|:-----------|------:|
| deepvk/USER-bge-m3                                          | **523.4** | **22.5** | **1371.1**  |    0.799 | 0.709      |  1024 |
| BAAI/bge-m3                                                 | 523.4     | 22.5     | 2166.0    |    0.787 | 0.696      |  1024 |
| intfloat/multilingual-e5-large-instruct                     | 501.5     | 25.71    | 2136.0    |    0.784 | 0.684      |  1024 |
| intfloat/multilingual-e5-large                              | 506.8     | 30.8     | 2135.9389 |    0.78  | 0.686      |  1024 |
| deepvk/USER-base                                            | 33.1      | **12.2** | 473.2402      |    0.772 | 0.688      |   768 |    
| sentence-transformers/paraphrase-multilingual-mpnet-base-v2 | **20.5**  | **19.9** | **1081.8485** |    0.762 |            |   768 |

##### Ранжирование моделей по задачам.
Подсвечены наилучшие модели по каждой из задач. 

| model                                                       | STS      | PI       | NLI  | SA       | TI   | IA       | IC       | ICX      | NE1  | NE2  |
| :---------------------------------------------------------- | :------- | :------- | :--- | :------- | :--- | :------- | :------- | :------- | :--- | :--- |
| deepvk/USER-bge-m3                                          | **0.87** | **0.76** | 0.58 | **0.82** | 0.97 | 0.79     | 0.81     | **0.78** | 0.28 | 0.43 |
| BAAI/bge-m3                                                 | 0.86     | 0.75     | 0.51 | **0.82** | 0.97 | 0.79     | 0.81     | **0.78** | 0.24 | 0.42 |
| intfloat/multilingual-e5-large-instruct                     | 0.86     | 0.74     | 0.47 | 0.81     | 0.98 | 0.8      | **0.82** | 0.77     | 0.21 | 0.35 |
| intfloat/multilingual-e5-large                              | 0.86     | 0.73     | 0.47 | 0.81     | 0.98 | 0.8      | 0.82     | 0.77     | 0.24 | 0.37 |
| deepvk/USER-base                                            | 0.85     | 0.74     | 0.48 | 0.81     | 0.99 | **0.81** | 0.8      | 0.7      | 0.29 | 0.41 |
| sentence-transformers/paraphrase-multilingual-mpnet-base-v2 | 0.85     | 0.66     | 0.54 | 0.79     | 0.95 | 0.78     | 0.79     | 0.74     |      |      |


## Дообучение моделей
Дообучение моделей не требуется

## Выводы

Топ отобранных моделей по приоритетности использования:
1) sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (супер быстрая модель, но менее качественная чем отсальные)
2) deepvk/USER-base (медленная, но качество среднее)
3) deepvk/USER-bge-m3 (супер медленная, но с лучшим качеством)